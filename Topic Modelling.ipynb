{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary libraries that we need for project work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#nltk.download(\"stopwords\")\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas._config.config.CallableDynamicDoc at 0x23639b0f790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20973</td>\n",
       "      <td>We present novel understandings of the Gamma...</td>\n",
       "      <td>Closed-form Marginal Likelihood in Gamma-Poiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20974</td>\n",
       "      <td>Meteorites contain minerals from Solar Syste...</td>\n",
       "      <td>Laboratory mid-IR spectra of equilibrated and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20975</td>\n",
       "      <td>Frame aggregation is a mechanism by which mu...</td>\n",
       "      <td>Case For Static AMSDU Aggregation in WLANs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20976</td>\n",
       "      <td>Milky Way open clusters are very diverse in ...</td>\n",
       "      <td>The $Gaia$-ESO Survey: the inner disk intermed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20977</td>\n",
       "      <td>Proving that a cryptographic protocol is cor...</td>\n",
       "      <td>Witness-Functions versus Interpretation-Functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>29957</td>\n",
       "      <td>We approach the problem of implementing mixe...</td>\n",
       "      <td>Supporting mixed-datatype matrix multiplicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>29958</td>\n",
       "      <td>In the theory of Markov decision processes (...</td>\n",
       "      <td>An axiomatic basis for Blackwell optimality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>29959</td>\n",
       "      <td>GeneVis is a web-based tool to visualize com...</td>\n",
       "      <td>GeneVis - An interactive visualization tool fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>29960</td>\n",
       "      <td>This paper quantifies the effect of speed ca...</td>\n",
       "      <td>Quantifying the causal effect of speed cameras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>29961</td>\n",
       "      <td>We show that the vertices and edges of a $d$...</td>\n",
       "      <td>Cube-magic labelings of grids</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8989 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                           ABSTRACT  \\\n",
       "0     20973    We present novel understandings of the Gamma...   \n",
       "1     20974    Meteorites contain minerals from Solar Syste...   \n",
       "2     20975    Frame aggregation is a mechanism by which mu...   \n",
       "3     20976    Milky Way open clusters are very diverse in ...   \n",
       "4     20977    Proving that a cryptographic protocol is cor...   \n",
       "...     ...                                                ...   \n",
       "8984  29957    We approach the problem of implementing mixe...   \n",
       "8985  29958    In the theory of Markov decision processes (...   \n",
       "8986  29959    GeneVis is a web-based tool to visualize com...   \n",
       "8987  29960    This paper quantifies the effect of speed ca...   \n",
       "8988  29961    We show that the vertices and edges of a $d$...   \n",
       "\n",
       "                                                  TITLE  \n",
       "0     Closed-form Marginal Likelihood in Gamma-Poiss...  \n",
       "1     Laboratory mid-IR spectra of equilibrated and ...  \n",
       "2            Case For Static AMSDU Aggregation in WLANs  \n",
       "3     The $Gaia$-ESO Survey: the inner disk intermed...  \n",
       "4     Witness-Functions versus Interpretation-Functi...  \n",
       "...                                                 ...  \n",
       "8984  Supporting mixed-datatype matrix multiplicatio...  \n",
       "8985        An axiomatic basis for Blackwell optimality  \n",
       "8986  GeneVis - An interactive visualization tool fo...  \n",
       "8987  Quantifying the causal effect of speed cameras...  \n",
       "8988                      Cube-magic labelings of grids  \n",
       "\n",
       "[8989 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chin= pd.read_csv(\"test.csv\")\n",
    "chin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chin.ABSTRACT=chin.ABSTRACT.str.lower()\n",
    "chin.TITLE=chin.TITLE.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)\n",
    "chin.ABSTRACT= chin.ABSTRACT.str.replace('[{}]'.format(string.punctuation), ' ')\n",
    "chin.TITLE=chin.TITLE.str.replace(\"[{}]\".format(string.punctuation),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chin.ABSTRACT = chin.ABSTRACT.str.replace(r'\\n', ' ')\n",
    "chin.ABSTRACT = chin.ABSTRACT.str.replace(r'\\\\', ' ')\n",
    "chin.ABSTRACT = chin.ABSTRACT.str.replace(r'\\t', ' ')\n",
    "chin.TITLE = chin.TITLE.str.replace(r'\\n', ' ')\n",
    "chin.TITLE = chin.TITLE.str.replace(r'\\\\', ' ')\n",
    "chin.TITLE = chin.TITLE.str.replace(r'\\t', ' ')\n",
    "chin.ABSTRACT = chin.ABSTRACT.apply(lambda x: ' '.join(x.split()))\n",
    "chin.TITLE = chin.TITLE.apply(lambda x: ' '.join(x.split()))\n",
    "x=chin.ABSTRACT\n",
    "y=chin.TITLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "ss = WordNetLemmatizer()\n",
    "def stem_sentences(sentence):\n",
    "    tokens = sentence.split()\n",
    "    stemmed_tokens = [ss.lemmatize(token) for token in tokens]\n",
    "    return stemmed_tokens#' '.join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stem_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-07f424bb8c14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem_sentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem_sentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stem_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "x.apply(stem_sentences)\n",
    "y.apply(stem_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_list=x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=x.tolist()\n",
    "#y=y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['w']]\n"
     ]
    }
   ],
   "source": [
    "def tokenization_s(data): # same can be achieved for words tokens\n",
    "    s_new = []\n",
    "    for sent in (data[:][0]): #For NumpY = sentences[:]\n",
    "        s_token = sent_tokenize(sent)\n",
    "        if s_token != ' ':\n",
    "            s_new.append(s_token)\n",
    "        return s_new\n",
    "x=tokenization_s(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix= [dictionary.doc2bow(rev) for rev in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda=gensim.models.ldamodel.LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lda_model = lda(corpus=doc_term_matrix,id2word=dictionary,num_topics=3,random_state=88,\n",
    "                chunksize=100,passes=50,iterations=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '1.000*\"w\"'), (1, '1.000*\"w\"'), (2, '1.000*\"w\"')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el816424321133387367256207385\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el816424321133387367256207385_data = {\"mdsDat\": {\"x\": [0.0, 0.0, 0.0], \"y\": [0.0, 0.0, 0.0], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [35.8805288112006, 34.18766456283138, 29.931806625968022]}, \"tinfo\": {\"Term\": [\"w\", \"w\", \"w\", \"w\"], \"Freq\": [1.0, 0.3588052988052368, 0.34187665581703186, 0.2993180751800537], \"Total\": [1.0, 1.0000000298023224, 1.0000000298023224, 1.0000000298023224], \"Category\": [\"Default\", \"Topic1\", \"Topic2\", \"Topic3\"], \"logprob\": [1.0, 0.0, 0.0, 0.0], \"loglift\": [1.0, 0.0, 0.0, 0.0]}, \"token.table\": {\"Topic\": [], \"Freq\": [], \"Term\": []}, \"R\": 1, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el816424321133387367256207385\", ldavis_el816424321133387367256207385_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el816424321133387367256207385\", ldavis_el816424321133387367256207385_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el816424321133387367256207385\", ldavis_el816424321133387367256207385_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=         x    y  topics  cluster       Freq\n",
       "topic                                      \n",
       "1      0.0  0.0       1        1  35.880529\n",
       "2      0.0  0.0       2        1  34.187665\n",
       "0      0.0  0.0       3        1  29.931807, topic_info=  Term      Freq  Total Category  logprob  loglift\n",
       "0    w  1.000000    1.0  Default      1.0      1.0\n",
       "0    w  0.358805    1.0   Topic1      0.0      0.0\n",
       "0    w  0.341877    1.0   Topic2      0.0      0.0\n",
       "0    w  0.299318    1.0   Topic3      0.0      0.0, token_table=Empty DataFrame\n",
       "Columns: [Topic, Freq, Term]\n",
       "Index: [], R=1, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 3, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis=pyLDAvis.gensim.prepare(lda_model,doc_term_matrix,dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence: 1.0\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "cmlda=CoherenceModel(model=lda_model,texts=x,dictionary=dictionary,coherence=\"c_v\")\n",
    "clda=cmlda.get_coherence()\n",
    "print(\"\\nCoherence:\",clda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "perplexity -0.9479678549346175\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nperplexity\", lda_model.log_perplexity(doc_term_matrix,total_docs=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
